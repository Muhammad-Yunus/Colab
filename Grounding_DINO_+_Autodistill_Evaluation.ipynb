{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammad-Yunus/Colab/blob/main/Grounding_DINO_%2B_Autodistill_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE2JHng4IBC0"
      },
      "source": [
        "![Autodistill banner](https://camo.githubusercontent.com/29d0935e1b88b0ebb784c22ef6dad74e998ddb8d7f34fec315efe2279e5d9d1d/68747470733a2f2f6d656469612e726f626f666c6f772e636f6d2f6f70656e2d736f757263652f6175746f64697374696c6c2f6175746f64697374696c6c2d62616e6e65722e6a70673f32)\n",
        "\n",
        "# Grounding DINO + Autodistill Evaluation\n",
        "\n",
        "This notebook contains the code used to evaluate Grounding DINO for our Autodistill + Grounding DINO Evaluation blog post.\n",
        "\n",
        "We will use Grounding DINO to annotate images in five datasets and visualize the results for 16 images in each dataset.\n",
        "\n",
        "## Configure GPU\n",
        "\n",
        "First, make sure you are using a GPU in this Notebook. Cclick Edit -> Notebook settings -> Hardware accelerator, set it to GPU, and then click Save.\n",
        "\n",
        "## Install Dependencies\n",
        "\n",
        "Next, install the required dependencies by running the code cell below."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "xkJFAEvw3d-O"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(\"HOME:\", HOME)"
      ],
      "metadata": {
        "id": "uLRz7KlO2eMv",
        "outputId": "cd6109dc-5614-417c-8547-c9faab1177ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HOME: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zp_iQUiIflc"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow autodistill autodistill-grounding-dino supervision -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOQ5RSYTKDBy"
      },
      "source": [
        "## Download a Dataset\n",
        "\n",
        "First, we need a dataset with which to work. Below, paste in a URL to any dataset on Roboflow Universe. You can also download data on your private account by uncommenting the commented code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHc2pgtnH3k_"
      },
      "outputs": [],
      "source": [
        "import roboflow\n",
        "\n",
        "roboflow.login()\n",
        "\n",
        "datasets = [\n",
        "    \"https://universe.roboflow.com/mohamed-traore-2ekkp/taco-trash-annotations-in-context/model/16\",\n",
        "    \"https://universe.roboflow.com/roboflow-universe-projects/retail-coolers/model/12\",\n",
        "    \"https://universe.roboflow.com/roboflow-universe-projects/people-and-ladders/model/4\",\n",
        "    \"https://universe.roboflow.com/roboflow-universe-projects/safety-cones-vfrj2/model/4\",\n",
        "    \"https://universe.roboflow.com/roboflow-universe-projects/people-detection-thermal/deploy/5\"\n",
        "]\n",
        "\n",
        "for dataset in datasets:\n",
        "  roboflow.download_dataset(dataset_url=dataset, model_format=\"yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"79mx7RziLPHPZMmphjFI\")\n",
        "project = rf.workspace(\"learning-kqfkj\").project(\"skissors-detection\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")\n",
        ""
      ],
      "metadata": {
        "id": "3-55CxTtwr5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bjXknigMgqF"
      },
      "source": [
        "## Import Dependencies\n",
        "\n",
        "Below, we import the dependencies required for our project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3X_nnrUIb-Z"
      },
      "outputs": [],
      "source": [
        "from autodistill_grounding_dino import GroundingDINO\n",
        "from autodistill.detection import CaptionOntology\n",
        "import supervision as sv\n",
        "import cv2\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "\n",
        "torch.use_deterministic_algorithms(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW_YGLv1Mm3Q"
      },
      "source": [
        "## Label Images with Grounding DINO\n",
        "\n",
        "Below, we set an \"ontology\". Ontologies map prompts -- text given to a model for use in labelling data -- to the labels you want your dataset to include.\n",
        "\n",
        "For example, the ontology `\"container\": \"shipping container\"` will send the prompt \"container\" to the base model (in this example Grounding DINO). All objects matching that prompt will be labelled \"shipping container\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "3VXD6dU5J3oR",
        "outputId": "74676603-7576-484a-860c-bc586b873032",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trying to load grounding dino directly\n",
            "final text_encoder_type: bert-base-uncased\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n"
          ]
        }
      ],
      "source": [
        "DATASET_FOLDER = \"./Skissors-Detection-1\"\n",
        "PROJECT_NAME = \"Scissors Detection\"\n",
        "ONTOLOGY = {\n",
        "    \"scissors\": \"scissors\"\n",
        "}\n",
        "\n",
        "base_model = GroundingDINO(ontology=CaptionOntology(ONTOLOGY))\n",
        "\n",
        "folder = os.path.join(DATASET_FOLDER, \"valid/images/\")\n",
        "\n",
        "image_names = os.listdir(folder)\n",
        "\n",
        "images = {}\n",
        "annotations = {}\n",
        "\n",
        "#all_images = []\n",
        "#titles = []\n",
        "\n",
        "for image_name in image_names:\n",
        "\n",
        "  # find full path of the image /path/to/file.jpg\n",
        "  image_name = os.path.join(folder, image_name)\n",
        "\n",
        "  if not image_name.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "    print(image_name)\n",
        "    continue\n",
        "\n",
        "  predictions = base_model.predict(image_name)\n",
        "\n",
        "  image = cv2.imread(image_name)\n",
        "\n",
        "  annotator = sv.BoxAnnotator()\n",
        "\n",
        "  predictions = predictions[predictions.confidence > 0.5]\n",
        "\n",
        "  # annotated_image = annotator.annotate(\n",
        "  #     scene=image,\n",
        "  #     detections=predictions\n",
        "  # )\n",
        "\n",
        "  annotations[image_name] = predictions\n",
        "  images[image_name] = image\n",
        "  #all_images.append(annotated_image)\n",
        "  #titles.append(i.split(\".\")[0])\n",
        "\n",
        "#sv.plot_images_grid(all_images, grid_size=(4, 4), titles=titles, size=(24, 24))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detections = annotations['./Skissors-Detection-1/valid/images/IMG_20240914_081441_jpg.rf.34c9b349af988aa081cc3d71466300d0.jpg']"
      ],
      "metadata": {
        "id": "h0jaTjNV6bhp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detections.confidence"
      ],
      "metadata": {
        "id": "eqz87Dvi66z7",
        "outputId": "6dafa254-53df-4b19-e38e-d57b4e654d3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9611151], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detections.class_id"
      ],
      "metadata": {
        "id": "gyA6MaKz7Iz9",
        "outputId": "77594450-013b-4094-e3fb-3aa9ba6b9ca4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ANNOTATIONS_DIRECTORY = os.path.join(HOME, 'annotations')\n",
        "\n",
        "MIN_IMAGE_AREA_PERCENTAGE = 0.002\n",
        "MAX_IMAGE_AREA_PERCENTAGE = 0.80\n",
        "APPROXIMATION_PERCENTAGE = 0.75\n",
        "\n",
        "CLASSES = [\"scissors\"]"
      ],
      "metadata": {
        "id": "kysgTuR12U-d"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y supervision\n",
        "!pip install -q supervision==0.6.0\n",
        "\n",
        "import supervision as sv\n",
        "print(sv.__version__)"
      ],
      "metadata": {
        "id": "VahP3MlL7j9H",
        "outputId": "943f7762-f20c-4f3c-9f5f-7cc3ab132446",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: supervision 0.6.0\n",
            "Uninstalling supervision-0.6.0:\n",
            "  Successfully uninstalled supervision-0.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "rf-groundingdino 0.1.2 requires supervision>=0.8.0, but you have supervision 0.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sv.Dataset(\n",
        "    classes=CLASSES,\n",
        "    images=images,\n",
        "    annotations=annotations\n",
        ").as_pascal_voc(\n",
        "    annotations_directory_path=ANNOTATIONS_DIRECTORY,\n",
        "    min_image_area_percentage=MIN_IMAGE_AREA_PERCENTAGE,\n",
        "    max_image_area_percentage=MAX_IMAGE_AREA_PERCENTAGE,\n",
        "    approximation_percentage=APPROXIMATION_PERCENTAGE\n",
        ")"
      ],
      "metadata": {
        "id": "uTHrUQw32ngc",
        "outputId": "d1f8515b-9b22-4cc4-8c15-6640f5da6f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'supervision' has no attribute 'Dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-039dd5c48b5d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m sv.Dataset(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCLASSES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mannotations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_pascal_voc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'supervision' has no attribute 'Dataset'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}